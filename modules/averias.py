import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import numpy as np
from utils.helpers import find_site_column, parse_datetime_column
from io import BytesIO

def create_site_location_mapping(df_proyectos):
    """Crea un mapeo √∫nico de sites a ubicaciones geogr√°ficas"""
    if df_proyectos is None:
        return pd.DataFrame()
    
    required_cols = ['SITE_NAME', 'Regi√≥n', 'Provincia', 'Distrito', 'Localidad']
    existing_cols = [col for col in required_cols if col in df_proyectos.columns]
    
    if len(existing_cols) < 2:
        return pd.DataFrame()
    
    return df_proyectos[existing_cols].drop_duplicates()

def filter_averias_by_geography(df_averias, df_proyectos, region_sel=None, provincia_sel=None, distrito_sel=None, localidad_sel=None):
    """
    Filtra aver√≠as por jerarqu√≠a geogr√°fica sin duplicar registros
    """
    if df_proyectos is None:
        return df_averias.copy()
    
    # Crear mapeo √∫nico
    required_cols = ['SITE_NAME', 'Regi√≥n', 'Provincia', 'Distrito', 'Localidad']
    existing_cols = [col for col in required_cols if col in df_proyectos.columns]
    
    if len(existing_cols) < 2:
        return df_averias.copy()
    
    site_mapping = df_proyectos[existing_cols].drop_duplicates()
    
    # Aplicar filtros jer√°rquicos al mapeo
    filtered_mapping = site_mapping.copy()
    
    if region_sel and "Regi√≥n" in filtered_mapping.columns:
        filtered_mapping = filtered_mapping[filtered_mapping["Regi√≥n"].isin(region_sel)]
    if provincia_sel and "Provincia" in filtered_mapping.columns:
        filtered_mapping = filtered_mapping[filtered_mapping["Provincia"].isin(provincia_sel)]
    if distrito_sel and "Distrito" in filtered_mapping.columns:
        filtered_mapping = filtered_mapping[filtered_mapping["Distrito"].isin(distrito_sel)]
    if localidad_sel and "Localidad" in filtered_mapping.columns:
        filtered_mapping = filtered_mapping[filtered_mapping["Localidad"].isin(localidad_sel)]
    
    # Obtener sites √∫nicos que cumplen criterios geogr√°ficos
    sites_validos = filtered_mapping["SITE_NAME"].unique()
    
    # Filtrar aver√≠as por estos sites
    site_column = find_site_column(df_averias)
    if site_column is None:
        return df_averias.copy()
    
    df_filtered = df_averias[df_averias[site_column].isin(sites_validos)].copy()
    
    # Agregar informaci√≥n geogr√°fica
    site_geo_info = filtered_mapping.groupby("SITE_NAME").first().reset_index()
    df_result = df_filtered.merge(
        site_geo_info,
        how="left",
        left_on=site_column,
        right_on="SITE_NAME"
    )
    
    return df_result

def create_averias_dashboard(df_averias, df_proyectos):
    """
    Crea el dashboard completo de aver√≠as
    """
    st.markdown('<h2 class="module-header">üìä An√°lisis de Aver√≠as</h2>', unsafe_allow_html=True)
    
    if df_averias is None:
        st.warning("‚ö†Ô∏è No se ha cargado el archivo de Aver√≠as")
        st.info("Sube un archivo CSV desde el panel lateral para ver el an√°lisis.")
        return
    
    # === FORMATEAR DATASET ===
    df_formatted = df_averias.copy()
    
    # Normalizar nombres de columnas a min√∫sculas
    df_formatted.columns = df_formatted.columns.str.lower()
    
    # Formatear columnas geogr√°ficas a may√∫sculas si existen
    geo_columns = ['regi√≥n', 'provincia', 'distrito', 'localidad', 'region']
    for col in geo_columns:
        if col in df_formatted.columns:
            df_formatted[col] = df_formatted[col].astype(str).str.upper()
    
    # Formatear columnas de estado
    status_columns = ['alarm_status', 'status', 'estado']
    for col in status_columns:
        if col in df_formatted.columns:
            df_formatted[col] = df_formatted[col].astype(str).str.lower()
    
    # Usar dataset formateado de aqu√≠ en adelante
    df_averias = df_formatted

    # Convertir start_time y end_time
    df_averias, start_time_date_conversion_success = parse_datetime_column(df_averias, "start_time")
    df_averias, _ = parse_datetime_column(df_averias, "end_time", create_derived_fields=False)
        
    # Usar el DataFrame principal para el resto del an√°lisis
    df_averias_processed = df_averias
    
    # M√©tricas iniciales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Aver√≠as", f"{len(df_averias_processed):,}")
    
    with col2:
        if "alarm_status" in df_averias_processed.columns:
            averias_activas = len(df_averias_processed[df_averias_processed["alarm_status"] == "active"])
            
            # M√©trica arriba
            st.metric("Aver√≠as Activas", averias_activas)
            
            # Bot√≥n debajo (solo si hay aver√≠as)
            if averias_activas > 0:
                # Preparar datos
                averias_activas_all = df_averias_processed[df_averias_processed["alarm_status"] == "active"]
                site_col = find_site_column(averias_activas_all)
                essential_columns = ["start_time", "end_time"]
                if site_col:
                    essential_columns.append(site_col)
                essential_columns.extend(["cell_name", "alarm_id", "alarm_name", "alarm_status"])
                download_columns = [col for col in essential_columns if col in averias_activas_all.columns]
                
                # Ordenar por start_time de m√°s antiguo a m√°s reciente
                if "start_time" in averias_activas_all.columns:
                    averias_activas_all = averias_activas_all.sort_values("start_time", ascending=True)
                
                # Crear Excel
                buffer = BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    averias_activas_all[download_columns].to_excel(
                        writer, 
                        sheet_name='Averias_Activas', 
                        index=False
                    )
                excel_data = buffer.getvalue()
                
                # Bot√≥n de descarga
                st.download_button(
                    label="üì• Descargar",
                    data=excel_data,
                    file_name=f"averias_activas_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="averias_activas_download",
                    help=f"Descargar {averias_activas} aver√≠as activas en Excel"
                )
        else:
            st.metric("Aver√≠as Activas", "N/A")

    with col3:
        site_col = find_site_column(df_averias_processed)
        if site_col:
            st.metric("Sites √önicos", df_averias_processed[site_col].nunique())
        else:
            st.metric("Sites √önicos", "N/A")
    
    with col4:
        if df_proyectos is not None:
            st.metric("Proyectos Disponibles", f"{len(df_proyectos):,}")
        else:
            st.metric("Proyectos Disponibles", "No cargado")
    
    # Solo mostrar filtros geogr√°ficos si tenemos datos de proyectos
    if df_proyectos is not None and any(col in df_proyectos.columns for col in ['Regi√≥n', 'Provincia', 'Distrito', 'Localidad']):
        st.subheader("üó∫Ô∏è Filtros Geogr√°ficos Jer√°rquicos")
        
        filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)
        
        # Filtros jer√°rquicos
        df_temp = df_proyectos.copy()
        
        with filter_col1:
            if "Regi√≥n" in df_proyectos.columns:
                regiones = sorted(df_proyectos["Regi√≥n"].dropna().unique())
                region_sel = st.multiselect("üåç Regi√≥n", regiones, key="averias_region")
                if region_sel:
                    df_temp = df_temp[df_temp["Regi√≥n"].isin(region_sel)]
            else:
                region_sel = None
        
        with filter_col2:
            if "Provincia" in df_temp.columns:
                provincias = sorted(df_temp["Provincia"].dropna().unique())
                provincia_sel = st.multiselect("üèõÔ∏è Provincia", provincias, key="averias_provincia")
                if provincia_sel:
                    df_temp = df_temp[df_temp["Provincia"].isin(provincia_sel)]
            else:
                provincia_sel = None
        
        with filter_col3:
            if "Distrito" in df_temp.columns:
                distritos = sorted(df_temp["Distrito"].dropna().unique())
                distrito_sel = st.multiselect("üèòÔ∏è Distrito", distritos, key="averias_distrito")
                if distrito_sel:
                    df_temp = df_temp[df_temp["Distrito"].isin(distrito_sel)]
            else:
                distrito_sel = None
        
        with filter_col4:
            if "Localidad" in df_temp.columns:
                localidades = sorted(df_temp["Localidad"].dropna().unique())
                localidad_sel = st.multiselect("üìç Localidad", localidades, key="averias_localidad")
            else:
                localidad_sel = None
        
        # Aplicar filtros
        if any([region_sel, provincia_sel, distrito_sel, localidad_sel]):
            df_filtrado = filter_averias_by_geography(
                df_averias_processed, df_proyectos, 
                region_sel, provincia_sel, distrito_sel, localidad_sel
            )
        else:
            df_filtrado = df_averias_processed.copy()
    else:
        df_filtrado = df_averias_processed.copy()
        st.info("‚ÑπÔ∏è Carga el archivo de Proyectos para usar filtros geogr√°ficos")
    
    # Eliminar duplicados si existe alarm_id
    if "alarm_id" in df_filtrado.columns:
        df_filtrado = df_filtrado.drop_duplicates(subset=["alarm_id"])
    
    result_col1, result_col2, result_col3 = st.columns(3)
    with result_col1:
        delta = len(df_filtrado) - len(df_averias_processed)
        st.metric("Aver√≠as Filtradas", f"{len(df_filtrado):,}", delta=delta)
    
    with result_col2:
        if "alarm_status" in df_filtrado.columns:
            activas_filtradas = len(df_filtrado[df_filtrado["alarm_status"] == "active"])
            st.metric("Activas Filtradas", activas_filtradas)
    
    with result_col3:
        site_col = find_site_column(df_filtrado)
        if site_col:
            sites_filtrados = df_filtrado[site_col].nunique()
            st.metric("Sites √önicos", sites_filtrados)
    
    # Tiempo Promedio de Resoluci√≥n por Site
    if "duration_minutes" in df_filtrado.columns and site_col:      
        # Calcular solo para aver√≠as resueltas (que tienen end_time)
        averias_resueltas = df_filtrado.dropna(subset=["duration_minutes"])
        
        if len(averias_resueltas) > 0:
            tiempo_col1, tiempo_col2, tiempo_col3 = st.columns(3)
            
            with tiempo_col1:
                avg_resolution = averias_resueltas["duration_minutes"].mean()
                st.metric("‚è±Ô∏è Tiempo Promedio Global", f"{avg_resolution:.1f} min")
            
            with tiempo_col2:
                median_resolution = averias_resueltas["duration_minutes"].median()
                st.metric("üìä Tiempo Mediano", f"{median_resolution:.1f} min")
            
            with tiempo_col3:
                max_resolution = averias_resueltas["duration_minutes"].max()
                st.metric("‚ö†Ô∏è Mayor Tiempo", f"{max_resolution:.1f} min")

            # Top/Bottom sites por tiempo de resoluci√≥n
            ranking_col1, ranking_col2 = st.columns(2)
            
            with ranking_col1:
                # Sites con mayor tiempo de resoluci√≥n
                site_avg_time = averias_resueltas.groupby(site_col)["duration_minutes"].agg(['mean', 'count']).reset_index()
                site_avg_time = site_avg_time[site_avg_time['count'] >= 3]  # Solo sites con 3+ aver√≠as
                top_slow = site_avg_time.nlargest(10, 'mean')
                
                if len(top_slow) > 0:
                    fig_slow = px.bar(
                        top_slow,
                        x='mean',
                        y=site_col,
                        orientation='h',
                        title="üåä Sites con Mayor Tiempo de Resoluci√≥n",
                        labels={'mean': 'Tiempo Promedio (min)', site_col: 'Site'},
                        color='mean',
                        color_continuous_scale='Reds'
                    )
                    fig_slow.update_layout(height=400)
                    st.plotly_chart(fig_slow, use_container_width=True)
            
            with ranking_col2:
                # Sites con aver√≠as activas con m√°s tiempo abierto
                if "alarm_status" in df_filtrado.columns:
                    averias_activas_actual = df_filtrado[df_filtrado["alarm_status"] == "active"]
                    
                    if len(averias_activas_actual) > 0 and "start_time" in averias_activas_actual.columns:
                        # Calcular tiempo transcurrido desde inicio de aver√≠a activa
                        now = pd.Timestamp.now()
                        averias_activas_actual['tiempo_abierto_horas'] = (now - averias_activas_actual['start_time']).dt.total_seconds() / 3600
                        
                        # Agrupar por site y obtener el promedio de tiempo abierto
                        site_tiempo_abierto = averias_activas_actual.groupby(site_col)['tiempo_abierto_horas'].agg(['mean', 'count']).reset_index()
                        site_tiempo_abierto = site_tiempo_abierto[site_tiempo_abierto['count'] >= 1]  # Al menos 1 aver√≠a activa
                        top_tiempo_abierto = site_tiempo_abierto.nlargest(10, 'mean')
                        
                        if len(top_tiempo_abierto) > 0:
                            fig_tiempo_abierto = px.bar(
                                top_tiempo_abierto,
                                x='mean',
                                y=site_col,
                                orientation='h',
                                title="‚è∞ Sites con aver√≠as activas m√°s tiempo abierto",
                                labels={'mean': 'Tiempo promedio abierto (horas)', site_col: 'Site'},
                                color='mean',
                                color_continuous_scale='Oranges'
                            )
                            fig_tiempo_abierto.update_layout(height=400)
                            st.plotly_chart(fig_tiempo_abierto, use_container_width=True)
                        else:
                            st.info("No hay suficientes aver√≠as activas para mostrar")
                    else:
                        st.info("No hay aver√≠as activas o faltan datos de tiempo")
                else:
                    st.warning("No se encontr√≥ la columna 'alarm_status'")

    # An√°lisis de distribuci√≥n
    st.subheader("üìà Distribuci√≥n de tiempos de resoluci√≥n")

    # Selector de site para an√°lisis detallado
    if "duration_minutes" in df_filtrado.columns and site_col:
        averias_resueltas = df_filtrado.dropna(subset=["duration_minutes"])
        sites_con_datos = averias_resueltas[site_col].value_counts()
        sites_disponibles = sites_con_datos[sites_con_datos >= 5].index.tolist()  # Solo sites con 5+ aver√≠as

        if sites_disponibles:
            selected_site_analysis = st.selectbox(
                "Seleccionar site para an√°lisis detallado:",
                ["Todos"] + sites_disponibles,
                key="site_analysis_selector"
            )
            
            if selected_site_analysis == "Todos":
                analysis_data = averias_resueltas
                title_suffix = "Todos los Sites"
            else:
                analysis_data = averias_resueltas[averias_resueltas[site_col] == selected_site_analysis]
                title_suffix = selected_site_analysis
            
            # Histograma de distribuci√≥n
            fig_hist = px.histogram(
                analysis_data,
                x="duration_minutes",
                nbins=30,
                title=f"Distribuci√≥n de tiempos de resoluci√≥n - {title_suffix}",
                labels={'duration_minutes': 'Tiempo de resoluci√≥n (minutos)', 'count': 'Frecuencia'}
            )
            st.plotly_chart(fig_hist, use_container_width=True)

    # === TOP SITES EN DOS COLUMNAS ===
    site_col = find_site_column(df_filtrado)
    if site_col:
        st.subheader("üèÜ Top Sites con aver√≠as")
        
        sites_col1, sites_col2 = st.columns(2)
        
        with sites_col1:
            # Top sites con m√°s aver√≠as totales
            top_sites_total = df_filtrado[site_col].value_counts().head(10)
            
            if len(top_sites_total) > 0:
                fig_top_sites_total = px.bar(
                    x=top_sites_total.values,
                    y=top_sites_total.index,
                    orientation='h',
                    title="üìä Top 10 Sites - Aver√≠as Totales",
                    labels={'x': 'N√∫mero de Aver√≠as', 'y': 'Site'},
                    color=top_sites_total.values,
                    color_continuous_scale='Blues'
                )
                fig_top_sites_total.update_layout(height=400, showlegend=False, yaxis={'categoryorder':'total ascending'})
                st.plotly_chart(fig_top_sites_total, use_container_width=True)
            else:
                st.info("No hay datos de aver√≠as para mostrar")
        
        with sites_col2:
            # Top sites con m√°s aver√≠as activas
            if "alarm_status" in df_filtrado.columns:
                averias_activas = df_filtrado[df_filtrado["alarm_status"] == "active"]
                
                if len(averias_activas) > 0:
                    top_sites_activas = averias_activas[site_col].value_counts().head(10)
                    
                    if len(top_sites_activas) > 0:
                        fig_top_sites_activas = px.bar(
                            x=top_sites_activas.values,
                            y=top_sites_activas.index[::-1],  # Invertir orden para mostrar descendente
                            orientation='h',
                            title="üö® Top 10 Sites - Aver√≠as Activas",
                            labels={'x': 'N√∫mero de Aver√≠as Activas', 'y': 'Site'},
                            color=top_sites_activas.values,
                            color_continuous_scale='Reds'
                        )
                        fig_top_sites_activas.update_layout(height=400, showlegend=False, yaxis={'categoryorder':'total ascending'})
                        st.plotly_chart(fig_top_sites_activas, use_container_width=True)
                    else:
                        st.info("No hay aver√≠as activas en los sites filtrados")
                else:
                    st.info("No hay aver√≠as activas para mostrar")
            else:
                st.warning("No se encontr√≥ la columna 'alarm_status'")
    
    # An√°lisis temporal
    if start_time_date_conversion_success:
        st.subheader("üìÖ An√°lisis Temporal")
        
        try:
            col_temp1, col_temp2 = st.columns(2)
            
            with col_temp1:
                # Aver√≠as por hora del d√≠a
                if "hour" in df_filtrado.columns:
                    hourly_alarms = df_filtrado.groupby("hour").size()
                    fig_hourly = px.bar(
                        x=hourly_alarms.index,
                        y=hourly_alarms.values,
                        title="Aver√≠as por Hora del D√≠a",
                        labels={'x': 'Hora', 'y': 'N√∫mero de Aver√≠as'}
                    )
                    st.plotly_chart(fig_hourly, use_container_width=True)
            
            with col_temp2:
                # Aver√≠as por d√≠a de la semana
                if "day_of_week" in df_filtrado.columns:
                    daily_alarms = df_filtrado.groupby("day_of_week").size()
                    fig_daily = px.bar(
                        x=daily_alarms.index,
                        y=daily_alarms.values,
                        title="Aver√≠as por D√≠a de la Semana",
                        labels={'x': 'D√≠a', 'y': 'N√∫mero de Aver√≠as'}
                    )
                    st.plotly_chart(fig_daily, use_container_width=True)
        
        except Exception as e:
            st.warning(f"No se pudo procesar el an√°lisis temporal: {str(e)}")
    else:
        st.info("‚ÑπÔ∏è No se pudieron procesar datos temporales. Verifica que existan columnas de fecha/hora v√°lidas.")
    
    # === MAPA DE AVER√çAS ACTIVAS ===
    if df_proyectos is not None and len(df_filtrado) > 0:
        st.subheader("üó∫Ô∏è Mapa de Aver√≠as Activas")
        
        # Filtrar solo aver√≠as activas
        if "alarm_status" in df_filtrado.columns:
            averias_activas = df_filtrado[df_filtrado["alarm_status"] == "active"]
            
            if len(averias_activas) > 0:
                site_col = find_site_column(averias_activas)
                if site_col:
                    # Obtener sites √∫nicos con aver√≠as activas
                    sites_activos = averias_activas[site_col].unique()
                    
                    # Verificar si tenemos coordenadas en proyectos
                    coord_cols_options = [
                        ("Latitud (WGS 84)", "Longitud (WGS 84)"),
                        ("Latitud", "Longitud"),
                        ("lat", "lon")
                    ]
                    
                    coord_cols = None
                    for lat_col, lon_col in coord_cols_options:
                        if lat_col in df_proyectos.columns and lon_col in df_proyectos.columns:
                            coord_cols = (lat_col, lon_col)
                            break
                    
                    if coord_cols:
                        # Filtrar proyectos que tienen aver√≠as activas
                        proyectos_activos = df_proyectos[
                            df_proyectos["SITE_NAME"].isin(sites_activos)
                        ].copy()
                        
                        # Limpiar y convertir coordenadas
                        proyectos_activos["lat"] = pd.to_numeric(proyectos_activos[coord_cols[0]], errors='coerce')
                        proyectos_activos["lon"] = pd.to_numeric(proyectos_activos[coord_cols[1]], errors='coerce')
                        
                        # Filtrar coordenadas v√°lidas
                        proyectos_mapa = proyectos_activos.dropna(subset=['lat', 'lon'])
                        
                        if len(proyectos_mapa) > 0:
                            # Buscar la columna de alarm_name normalizada (min√∫sculas)
                            alarm_name_col = None
                            for col in ["alarm_name", "alarm_Name", "Alarm_Name"]:
                                if col in averias_activas.columns:
                                    alarm_name_col = col
                                    break
                            
                            # Crear lista de columnas para el merge
                            merge_cols = [site_col]
                            if alarm_name_col:
                                merge_cols.append(alarm_name_col)
                            if "start_time" in averias_activas.columns:
                                merge_cols.append("start_time")
                            
                            # Agregar informaci√≥n de aver√≠as al mapa
                            mapa_data = proyectos_mapa.merge(
                                averias_activas[merge_cols],
                                left_on="SITE_NAME",
                                right_on=site_col,
                                how="inner"
                            )
                            
                            # Contar aver√≠as por site
                            alarmas_por_site = averias_activas.groupby(site_col).size().reset_index(name='num_alarmas')
                            mapa_data = mapa_data.merge(alarmas_por_site, left_on="SITE_NAME", right_on=site_col, how="left")
                            
                            # Preparar datos para hover
                            hover_data = {
                                "lat": False,
                                "lon": False,
                                "num_alarmas": True
                            }
                            
                            # Agregar campos disponibles al hover
                            hover_fields = ["Regi√≥n", "Provincia", "Distrito", "start_time"]
                            if alarm_name_col:
                                hover_fields.append(alarm_name_col)
                            
                            for col in hover_fields:
                                if col in mapa_data.columns:
                                    hover_data[col] = True
                            
                            # Crear mapa con plotly - USANDO PUNTOS SIMPLES
                            fig_mapa = px.scatter_mapbox(
                                mapa_data,
                                lat="lat",
                                lon="lon",
                                hover_name="SITE_NAME",
                                hover_data=hover_data,
                                color="Regi√≥n" if "Regi√≥n" in mapa_data.columns else "num_alarmas",
                                zoom=5,
                                title=f"üö® {len(mapa_data)} Sites con Aver√≠as Activas"
                            )
                            
                            # Si no hay regi√≥n para colorear, usar escala de rojos para num_alarmas
                            if "Regi√≥n" not in mapa_data.columns:
                                fig_mapa.update_traces(
                                    marker=dict(
                                        colorscale="Reds",
                                        colorbar=dict(title="N√∫mero de Alarmas")
                                    )
                                )
                            
                            # Configurar el mapa
                            fig_mapa.update_layout(
                                mapbox_style="open-street-map",
                                height=600,
                                showlegend=True,
                                title=f"üö® {len(mapa_data)} Sites con Aver√≠as Activas",
                                mapbox=dict(
                                    center=dict(lat=-9.19, lon=-75.02),  # Centro de Per√∫
                                    zoom=5
                                )
                            )
                            
                            st.plotly_chart(fig_mapa, use_container_width=True)
                            
                            # Mostrar estad√≠sticas del mapa
                            map_col1, map_col2, map_col3, map_col4 = st.columns(4)
                            
                            with map_col1:
                                st.metric("üó∫Ô∏è Sites Mapeados", len(mapa_data))
                            
                            with map_col2:
                                total_alarmas = mapa_data["num_alarmas"].sum()
                                st.metric("üö® Total Alarmas Activas", int(total_alarmas))
                            
                            with map_col3:
                                if "Regi√≥n" in mapa_data.columns:
                                    regiones_afectadas = mapa_data["Regi√≥n"].nunique()
                                    st.metric("üåç Regiones Afectadas", regiones_afectadas)
                            
                            with map_col4:
                                promedio_alarmas = mapa_data["num_alarmas"].mean()
                                st.metric("üìä Promedio Alarmas/Site", f"{promedio_alarmas:.1f}")
                        
                        else:
                            st.warning("‚ö†Ô∏è No se encontraron coordenadas v√°lidas para mostrar el mapa")
                    
                    else:
                        st.warning("‚ö†Ô∏è No se encontraron columnas de coordenadas en los datos de proyectos")
                        st.info("Columnas esperadas: 'Latitud (WGS 84)' y 'Longitud (WGS 84)' o similares")
                
                else:
                    st.warning("‚ö†Ô∏è No se encontr√≥ columna de sites en aver√≠as")
            
            else:
                st.info("‚ÑπÔ∏è No hay aver√≠as activas para mostrar en el mapa")
        
        else:
            st.warning("‚ö†Ô∏è No se encontr√≥ la columna 'alarm_status' para filtrar aver√≠as activas")
    
    # === TABLA DE DATOS FILTRADOS ===
    st.subheader("üìã Tabla de Aver√≠as")
    
    # Filtros adicionales por fechas y sites
    st.subheader("üîç Filtros Adicionales")
    
    # Aplicar filtros paso a paso
    df_temp_filtros = df_filtrado.copy()
    
    # === FILTRO POR RANGO DE FECHAS ===
    if "start_time" in df_filtrado.columns and start_time_date_conversion_success:
        st.markdown("**üìÖ Filtro por Rango de Fechas**")
        
        # Obtener rango de fechas disponible
        min_date = df_filtrado["start_time"].min().date()
        max_date = df_filtrado["start_time"].max().date()
        
        date_col1, date_col2 = st.columns(2)
        
        with date_col1:
            fecha_inicio = st.date_input(
                "Fecha de inicio:",
                value=min_date,
                min_value=min_date,
                max_value=max_date,
                key="averias_fecha_inicio"
            )
        
        with date_col2:
            fecha_fin = st.date_input(
                "Fecha de fin:",
                value=max_date,
                min_value=min_date,
                max_value=max_date,
                key="averias_fecha_fin"
            )
        
        # Validar y aplicar filtro de fechas
        if fecha_inicio <= fecha_fin:
            # Filtrar por rango de fechas
            df_temp_filtros = df_temp_filtros[
                (df_temp_filtros["start_time"].dt.date >= fecha_inicio) &
                (df_temp_filtros["start_time"].dt.date <= fecha_fin)
            ].copy()
            
            # Mostrar m√©tricas del filtro de fechas
            date_metrics_col1, date_metrics_col2, date_metrics_col3 = st.columns(3)
            
            with date_metrics_col1:
                delta_fechas = len(df_temp_filtros) - len(df_filtrado)
                st.metric("Registros en rango", f"{len(df_temp_filtros):,}", delta=delta_fechas)
            
            with date_metrics_col2:
                if "alarm_status" in df_temp_filtros.columns:
                    activas_rango = len(df_temp_filtros[df_temp_filtros["alarm_status"] == "active"])
                    st.metric("Activas en rango", activas_rango)
            
            with date_metrics_col3:
                dias_seleccionados = (fecha_fin - fecha_inicio).days + 1
                st.metric("D√≠as seleccionados", dias_seleccionados)
        else:
            st.error("‚ö†Ô∏è La fecha de inicio debe ser menor o igual a la fecha de fin")
    else:
        st.info("‚ÑπÔ∏è No hay datos de fecha v√°lidos para aplicar filtro temporal")
    
    # === FILTRO POR SITE NAME ===
    site_col = find_site_column(df_temp_filtros)
    if site_col:
        st.markdown("**üèóÔ∏è Filtro por Site Name**")
        
        # Obtener lista de sites √∫nicos en los datos filtrados por fecha
        sites_disponibles = sorted(df_temp_filtros[site_col].dropna().unique())
        
        if sites_disponibles:
            site_filter_col1, site_filter_col2 = st.columns([3, 1])
            
            with site_filter_col1:
                sites_seleccionados = st.multiselect(
                    "Seleccionar sites:",
                    options=sites_disponibles,
                    default=[],
                    key="averias_sites_filter",
                    help=f"Disponibles: {len(sites_disponibles)} sites √∫nicos"
                )
            
            with site_filter_col2:
                st.markdown("**Acciones r√°pidas:**")
                if st.button("Seleccionar todos", key="select_all_sites"):
                    st.session_state["averias_sites_filter"] = sites_disponibles
                    st.rerun()
                
                if st.button("Limpiar selecci√≥n", key="clear_sites"):
                    st.session_state["averias_sites_filter"] = []
                    st.rerun()
            
            # Aplicar filtro de sites si hay selecci√≥n
            if sites_seleccionados:
                df_temp_filtros = df_temp_filtros[
                    df_temp_filtros[site_col].isin(sites_seleccionados)
                ].copy()
                
                # Mostrar m√©tricas del filtro de sites
                site_metrics_col1, site_metrics_col2, site_metrics_col3 = st.columns(3)
                
                with site_metrics_col1:
                    st.metric("Sites seleccionados", len(sites_seleccionados))
                
                with site_metrics_col2:
                    registros_sites = len(df_temp_filtros)
                    st.metric("Registros filtrados", f"{registros_sites:,}")
                
                with site_metrics_col3:
                    if "alarm_status" in df_temp_filtros.columns:
                        activas_sites = len(df_temp_filtros[df_temp_filtros["alarm_status"] == "active"])
                        st.metric("Activas filtradas", activas_sites)
        else:
            st.warning("‚ö†Ô∏è No hay sites disponibles en el rango de fechas seleccionado")
    else:
        st.warning("‚ö†Ô∏è No se encontr√≥ columna de sites para filtrar")
    
    # Usar el DataFrame con todos los filtros aplicados
    df_tabla = df_temp_filtros
    
    # Controles de tabla
    table_col1, table_col2 = st.columns(2)

    with table_col1:
        max_rows = st.slider("N√∫mero de filas a mostrar:", 10, 500, 100, key="averias_rows")
    
    with table_col2:
        show_all_columns = st.checkbox("Mostrar todas las columnas", value=False, key="averias_show_all_columns")

    # Preparar columnas para mostrar
    if show_all_columns:
        display_columns = list(df_tabla.columns)
    else:
        # Mostrar columnas esenciales
        essential_columns = ["start_time", "end_time", "duration_minutes"]
        if site_col:
            essential_columns.append(site_col)
        essential_columns.extend(["cell_name", "alarm_id", "alarm_name", "alarm_status"])
        display_columns = [col for col in essential_columns if col in df_tabla.columns]
    
    # Mostrar datos
    st.dataframe(df_tabla[display_columns].head(max_rows), use_container_width=True, hide_index=True)
    
    # Botones de descarga
    download_col1, download_col2 = st.columns(2)
    
    with download_col1:
        # Bot√≥n de descarga CSV
        csv = df_tabla.to_csv(index=False)
        st.download_button(
            label="üì• Descargar CSV",
            data=csv,
            file_name=f"averias_filtradas_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv",
            key="averias_download_filtered_csv"
        )
    
    with download_col2:
        # Bot√≥n de descarga Excel
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df_tabla.to_excel(writer, sheet_name='Averias_Filtradas', index=False)
        excel_data = buffer.getvalue()
        
        st.download_button(
            label="üì• Descargar Excel",
            data=excel_data,
            file_name=f"averias_filtradas_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="averias_download_filtered_excel"
        )